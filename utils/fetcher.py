# scraper/fetcher.py
import requests
from bs4 import BeautifulSoup
import time
import logging

from pathlib import Path
import sys, os
sys.path.insert(0, str(Path(__file__).resolve().parent.parent))
from utils import ocr  # å¯¼å…¥è‡ªå®šä¹‰OCRæ¨¡å—
from urllib.parse import urlparse

# --- é…ç½®ä¸å¸¸é‡ ---
BASE_URL = "https://jwc.swjtu.edu.cn"

# å‘èµ·è¯·æ±‚ï¼Œå…è®¸é‡å®šå‘
response = requests.get(
    BASE_URL,
    timeout=5,
    allow_redirects=True,  # è‡ªåŠ¨è·Ÿéšé‡å®šå‘
    verify=True  # éªŒè¯ SSL è¯ä¹¦
)

# è§£ææœ€ç»ˆçš„ URL
final_url = response.url
parsed = urlparse(final_url)
final_protocol = parsed.scheme
if final_protocol == "http":
    BASE_URL = "http://jwc.swjtu.edu.cn"
    print("æ£€æµ‹åˆ°æ•™åŠ¡ä½¿ç”¨ HTTPï¼Œå·²åˆ‡æ¢ä¸º HTTP è®¿é—®ã€‚")

LOGIN_PAGE_URL = f"{BASE_URL}/service/login.html"
LOGIN_API_URL = f"{BASE_URL}/vatuu/UserLoginAction"
CAPTCHA_URL = f"{BASE_URL}/vatuu/GetRandomNumberToJPEG"
LOADING_URL = f"{BASE_URL}/vatuu/UserLoadingAction"
ALL_SCORES_URL = f"{BASE_URL}/vatuu/StudentScoreInfoAction?setAction=studentScoreQuery&viewType=studentScore&orderType=submitDate&orderValue=desc"
NORMAL_SCORES_URL = f"{BASE_URL}/vatuu/StudentScoreInfoAction?setAction=studentNormalMark"

HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36',
    'Origin': BASE_URL,
}

class ScoreFetcher:
    def __init__(self, username, password):
        self.username = username
        self.password = password
        self.session = requests.Session()
        self.session.headers.update(HEADERS)
        self.is_logged_in = False

    def login(self, max_retries=10, retry_delay=1):
        for attempt in range(1, max_retries + 1):
            print(f"--- ç™»å½•å°è¯• #{attempt}/{max_retries} ---")
            
            try:
                # 1. è·å–å¹¶è¯†åˆ«éªŒè¯ç 
                print("æ­£åœ¨è·å–éªŒè¯ç ...")
                captcha_params = {'test': int(time.time() * 1000)}
                response = self.session.get(CAPTCHA_URL, params=captcha_params, timeout=10)
                response.raise_for_status()
                captcha_code = ocr.classify(response.content)
                print(f"OCR è¯†åˆ«ç»“æœ: {captcha_code}")
                if not captcha_code or len(captcha_code) != 4:
                    print("éªŒè¯ç è¯†åˆ«å¤±è´¥ï¼Œè·³è¿‡æœ¬æ¬¡å°è¯•ã€‚")
                    if attempt < max_retries: time.sleep(retry_delay)
                    continue

                # 2. å°è¯•APIç™»å½•
                print("æ­£åœ¨å°è¯•ç™»å½•API...")
                login_payload = { 'username': self.username, 'password': self.password, 'ranstring': captcha_code, 'url': '', 'returnType': '', 'returnUrl': '', 'area': '' }
                response = self.session.post(LOGIN_API_URL, data=login_payload, headers={'Referer': LOGIN_PAGE_URL}, timeout=10)
                response.raise_for_status()
                login_result = response.json()

                if login_result.get('loginStatus') == '1':
                    print(f"APIéªŒè¯æˆåŠŸï¼{login_result.get('loginMsg')[0:5]}")
                    print("æ­£åœ¨è®¿é—®åŠ è½½é¡µé¢ä»¥å»ºç«‹å®Œæ•´ä¼šè¯...")
                    self.session.get(LOADING_URL, headers={'Referer': LOGIN_PAGE_URL}, timeout=10)
                    print("ä¼šè¯å»ºç«‹æˆåŠŸï¼Œå·²ç™»å½•ã€‚")
                    self.is_logged_in = True
                    return True
                else:
                    print(f"ç™»å½•APIå¤±è´¥: {login_result.get('loginMsg', 'æœªçŸ¥é”™è¯¯')}")
            
            except Exception as e:
                print(f"ç™»å½•è¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸: {e}")

            if attempt < max_retries:
                print(f"ç­‰å¾… {retry_delay} ç§’åé‡è¯•...")
                time.sleep(retry_delay)
        
        print(f"\nç™»å½•å¤±è´¥ {max_retries} æ¬¡ï¼Œç¨‹åºç»ˆæ­¢ã€‚")
        return False

    def get_all_scores(self):
        if not self.is_logged_in:
            print("é”™è¯¯ï¼šæœªç™»å½•ã€‚")
            return None

        print("\næ­£åœ¨æŸ¥è¯¢å…¨éƒ¨æˆç»©è®°å½•...")
        try:
            response = self.session.get(ALL_SCORES_URL, headers={'Referer': LOADING_URL}, timeout=15)
            response.raise_for_status()

            soup = BeautifulSoup(response.text, 'html.parser')
            score_table = soup.find('table', id='table3')
            if not score_table:
                print("é”™è¯¯ï¼šæœªæ‰¾åˆ°å…¨éƒ¨æˆç»©è¡¨æ ¼ã€‚")
                return None

            all_rows_data = []
            header = [th.text.strip() for th in score_table.find('tr').find_all('th')]
            
            for row in score_table.find_all('tr')[1:]:
                cols = [ele.text.strip() for ele in row.find_all('td')]
                if len(cols) == len(header):
                    all_rows_data.append(dict(zip(header, cols)))
            
            print(f"æˆåŠŸè·å–åˆ° {len(all_rows_data)} æ¡æ€»æˆç»©è®°å½•ã€‚")
            return all_rows_data

        except Exception as e:
            print(f"è·å–å…¨éƒ¨æˆç»©æ—¶å‡ºé”™: {e}")
            return None

    def get_normal_scores(self):
        if not self.is_logged_in:
            print("é”™è¯¯ï¼šæœªç™»å½•ã€‚")
            return None

        print("\næ­£åœ¨æŸ¥è¯¢å¹³æ—¶æˆç»©æ˜ç»†...")
        try:
            response = self.session.get(NORMAL_SCORES_URL, headers={'Referer': ALL_SCORES_URL}, timeout=15)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.text, 'html.parser')
            score_table = soup.find('table', id='table3')
            if not score_table:
                print("é”™è¯¯ï¼šæœªæ‰¾åˆ°å¹³æ—¶æˆç»©è¡¨æ ¼ã€‚")
                return None
            
            normal_scores_data = []
            current_course_info = {}
            for row in score_table.find_all('tr')[1:]:
                cols = row.find_all('td')
                if len(cols) == 11:
                    course_name = cols[3].text.strip()
                    if not current_course_info or current_course_info.get("è¯¾ç¨‹åç§°") != course_name:
                        if current_course_info:
                            normal_scores_data.append(current_course_info)
                        current_course_info = {
                            "è¯¾ç¨‹åç§°": course_name,
                            "æ•™å¸ˆ": cols[5].text.strip(),
                            "è¯¦æƒ…": []
                        }
                    
                    current_course_info["è¯¦æƒ…"].append({
                        "å¹³æ—¶æˆç»©åç§°": cols[6].text.strip(),
                        "æˆç»©": cols[8].text.strip(),
                        "å æ¯”": cols[7].text.strip(),
                        "æäº¤æ—¶é—´": cols[10].text.strip()
                    })
                
                elif len(cols) == 1 and cols[0].get('colspan') == '11':
                    if current_course_info:
                        current_course_info["æ€»ç»“"] = cols[0].text.strip()
            
            if current_course_info: # æ·»åŠ æœ€åä¸€ä¸ªè¯¾ç¨‹
                normal_scores_data.append(current_course_info)

            print(f"æˆåŠŸè·å–åˆ° {len(normal_scores_data)} é—¨è¯¾ç¨‹çš„å¹³æ—¶æˆç»©æ˜ç»†ã€‚")
            return normal_scores_data

        except Exception as e:
            print(f"è·å–å¹³æ—¶æˆç»©æ—¶å‡ºé”™: {e}")
            return None

    def get_combined_scores(self):
        """
        è·å–æ€»æˆç»©å’Œå¹³æ—¶æˆç»©ï¼Œå¹¶å°†å®ƒä»¬åˆå¹¶ã€‚
        """
        if not self.is_logged_in:
            print("é”™è¯¯ï¼šæœªç™»å½•ã€‚")
            return None

        all_scores = self.get_all_scores()
        time.sleep(1) # æ¨¡æ‹Ÿäººç±»è¡Œä¸º
        normal_scores = self.get_normal_scores()

        if not all_scores:
            print("æœªèƒ½è·å–æ€»æˆç»©ï¼Œæ— æ³•è¿›è¡Œåˆå¹¶ã€‚")
            raise Exception("æœªèƒ½è·å–æ€»æˆç»©ï¼Œæ— æ³•è¿›è¡Œåˆå¹¶ã€‚")

        if not normal_scores:
            print("æœªèƒ½è·å–å¹³æ—¶æˆç»©ã€‚")
            raise Exception("æœªèƒ½è·å–å¹³æ—¶æˆç»©ã€‚")

        # åˆ›å»ºä¸€ä¸ªå¿«é€ŸæŸ¥æ‰¾å¹³æ—¶æˆç»©çš„å­—å…¸
        # key: (è¯¾ç¨‹åç§°, æ•™å¸ˆ)
        normal_scores_map = {(ns['è¯¾ç¨‹åç§°'], ns['æ•™å¸ˆ']): {
            'è¯¦æƒ…': ns['è¯¦æƒ…'],
            'æ€»ç»“': ns.get('æ€»ç»“')  # åŒ…å«summaryä¿¡æ¯
        } for ns in normal_scores}
        
        # éå†æ€»æˆç»©ï¼Œå°†å¹³æ—¶æˆç»©è¯¦æƒ…åˆå¹¶è¿›å»
        for score_record in all_scores:
            key = (score_record['è¯¾ç¨‹åç§°'], score_record['æ•™å¸ˆ'])
            if key in normal_scores_map:
                normal_data = normal_scores_map[key]
                score_record['å¹³æ—¶æˆç»©è¯¦æƒ…'] = normal_data['è¯¦æƒ…']
                score_record['å¹³æ—¶æˆç»©æ€»ç»“'] = normal_data['æ€»ç»“']
            else:
                score_record['å¹³æ—¶æˆç»©è¯¦æƒ…'] = None
                score_record['å¹³æ—¶æˆç»©æ€»ç»“'] = None

        print("æ€»æˆç»©ä¸å¹³æ—¶æˆç»©åˆå¹¶å®Œæˆã€‚")
        return all_scores
   
import requests
from urllib.parse import urlparse

def detect_base_url(domain, test_path='/', timeout=5):
    """
    è‡ªåŠ¨æ£€æµ‹ç½‘ç«™å®é™…ä½¿ç”¨çš„åè®®ï¼ˆHTTP/HTTPSï¼‰
    é€šè¿‡å°è¯•è®¿é—®å¹¶è·Ÿéšé‡å®šå‘æ¥åˆ¤æ–­
    
    Args:
        domain: åŸŸåï¼Œå¦‚ 'jwc.swjtu.edu.cn'
        test_path: æµ‹è¯•è·¯å¾„ï¼Œé»˜è®¤ä¸ºæ ¹è·¯å¾„
        timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
    
    Returns:
        str: å®é™…ä½¿ç”¨çš„ BASE_URLï¼Œå¦‚ 'http://jwc.swjtu.edu.cn'
    """
    print(f"ğŸ” æ­£åœ¨æ£€æµ‹ {domain} çš„è®¿é—®åè®®...")
    
    # ä¼˜å…ˆå°è¯• HTTPSï¼ˆç°ä»£æ ‡å‡†ï¼‰
    for protocol in ['https', 'http']:
        test_url = f"{protocol}://{domain}{test_path}"
        
        try:
            print(f"  ğŸ“¡ å°è¯• {protocol.upper()} ...")
            
            # å‘èµ·è¯·æ±‚ï¼Œå…è®¸é‡å®šå‘
            response = requests.get(
                test_url,
                timeout=timeout,
                allow_redirects=True,  # è‡ªåŠ¨è·Ÿéšé‡å®šå‘
                verify=True  # éªŒè¯ SSL è¯ä¹¦
            )
            
            # è§£ææœ€ç»ˆçš„ URL
            final_url = response.url
            parsed = urlparse(final_url)
            final_protocol = parsed.scheme
            final_domain = parsed.netloc
            
            # æ£€æŸ¥æ˜¯å¦å‘ç”Ÿäº†é‡å®šå‘
            if response.history:
                print(f"  â†ªï¸  å‘ç”Ÿäº† {len(response.history)} æ¬¡é‡å®šå‘:")
                for i, resp in enumerate(response.history, 1):
                    print(f"      {i}. {resp.url} â†’ {resp.status_code} {resp.reason}")
            
            print(f"  âœ… æœ€ç»ˆè®¿é—®: {final_url}")
            print(f"  ğŸ” ä½¿ç”¨åè®®: {final_protocol.upper()}")
            print(f"  ğŸ“Š çŠ¶æ€ç : {response.status_code}")
            
            # æ£€æµ‹åˆ°åè®®é™çº§
            if protocol == 'https' and final_protocol == 'http':
                print(f"  âš ï¸  æœåŠ¡å™¨å°† HTTPS é‡å®šå‘åˆ° HTTP")
                print(f"  ğŸ’¡ å»ºè®®ç›´æ¥ä½¿ç”¨ HTTP åè®®ä»¥é¿å… Cookie é—®é¢˜")
            
            # æ„é€  BASE_URL
            base_url = f"{final_protocol}://{final_domain}"
            
            print(f"\nâœ¨ æ£€æµ‹å®Œæˆï¼ä½¿ç”¨: {base_url}\n")
            return base_url
            
        except requests.exceptions.SSLError as e:
            print(f"  âŒ SSL è¯ä¹¦é”™è¯¯")
            print(f"  ğŸ’¡ {protocol.upper()} ä¸å¯ç”¨ï¼Œç»§ç»­å°è¯•...")
            continue
            
        except requests.exceptions.ConnectionError as e:
            print(f"  âŒ è¿æ¥å¤±è´¥")
            print(f"  ğŸ’¡ {protocol.upper()} æ— æ³•è®¿é—®ï¼Œç»§ç»­å°è¯•...")
            continue
            
        except requests.exceptions.Timeout:
            print(f"  âŒ è¿æ¥è¶…æ—¶ï¼ˆ>{timeout}ç§’ï¼‰")
            continue
            
        except Exception as e:
            print(f"  âŒ æœªçŸ¥é”™è¯¯: {type(e).__name__}: {e}")
            continue
    
    # æ‰€æœ‰åè®®éƒ½å¤±è´¥ï¼Œé»˜è®¤ä½¿ç”¨ HTTP
    print(f"âš ï¸  æ— æ³•è‡ªåŠ¨æ£€æµ‹ï¼Œé»˜è®¤ä½¿ç”¨: http://{domain}\n")
    return f"http://{domain}"

if __name__ == "__main__":
    print(detect_base_url("jwc.swjtu.edu.cn"))